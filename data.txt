===================================
** train data for ten examples **
===================================
    tem   oxg   hum  carb  door  aircon
0  20.0  20.9  61.7  53.6     0       0
1  20.0  20.9  61.7  53.7     0       0
2  20.0  20.9  61.8  53.8     0       0
3  20.0  20.9  61.8  54.0     0       0
4  20.0  20.9  61.9  54.3     0       0 

===================================
** label data for ten examples **
===================================
   people
0       0
1       0
2       0
3       0
4       0 

==========================================
>>>>>> standstard preprocess done >>>>>
========================================== 

==========================================
>>>>>> split data process done >>>>>
>>>>> train amount 417 >>>>>>>>
>>>>> test amount 179 >>>>>>>>
========================================== 

=========================================================
<class 'sklearn.tree.tree.DecisionTreeClassifier'>
=========================================================
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
             precision    recall  f1-score   support

          0       0.89      0.89      0.89        35
          1       0.56      0.56      0.56         9
          2       1.00      1.00      1.00        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.96      0.96      0.96       179

[[31  4  0  0  0]
 [ 4  5  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.naive_bayes.GaussianNB'>
=========================================================
GaussianNB(priors=None)
             precision    recall  f1-score   support

          0       0.83      0.69      0.75        35
          1       0.33      0.44      0.38         9
          2       0.94      1.00      0.97        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.92      0.91      0.91       179

[[24  8  3  0  0]
 [ 5  4  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.linear_model.logistic.LogisticRegression'>
=========================================================
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
             precision    recall  f1-score   support

          0       0.74      0.71      0.72        35
          1       0.00      0.00      0.00         9
          2       0.82      1.00      0.90        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.85      0.89      0.87       179

[[25  0 10  0  0]
 [ 9  0  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.svm.classes.SVC'>
=========================================================
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
             precision    recall  f1-score   support

          0       0.79      0.97      0.87        35
          1       0.00      0.00      0.00         9
          2       0.98      1.00      0.99        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.90      0.94      0.92       179

[[34  0  1  0  0]
 [ 9  0  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.neighbors.classification.KNeighborsClassifier'>
=========================================================
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
             precision    recall  f1-score   support

          0       0.91      0.89      0.90        35
          1       0.60      0.67      0.63         9
          2       1.00      1.00      1.00        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.96      0.96      0.96       179

[[31  4  0  0  0]
 [ 3  6  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

send already
===================================
** train data for ten examples **
===================================
    tem   oxg   hum  carb  door  aircon
0  20.0  20.9  61.7  53.6     0       0
1  20.0  20.9  61.7  53.7     0       0
2  20.0  20.9  61.8  53.8     0       0
3  20.0  20.9  61.8  54.0     0       0
4  20.0  20.9  61.9  54.3     0       0 

===================================
** label data for ten examples **
===================================
   people
0       0
1       0
2       0
3       0
4       0 

==========================================
>>>>>> standstard preprocess done >>>>>
========================================== 

==========================================
>>>>>> split data process done >>>>>
>>>>> train amount 417 >>>>>>>>
>>>>> test amount 179 >>>>>>>>
========================================== 

=========================================================
<class 'sklearn.tree.tree.DecisionTreeClassifier'>
=========================================================
DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
             precision    recall  f1-score   support

          0       0.89      0.89      0.89        35
          1       0.56      0.56      0.56         9
          2       1.00      1.00      1.00        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.96      0.96      0.96       179

[[31  4  0  0  0]
 [ 4  5  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.naive_bayes.GaussianNB'>
=========================================================
GaussianNB(priors=None)
             precision    recall  f1-score   support

          0       0.83      0.69      0.75        35
          1       0.33      0.44      0.38         9
          2       0.94      1.00      0.97        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.92      0.91      0.91       179

[[24  8  3  0  0]
 [ 5  4  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.linear_model.logistic.LogisticRegression'>
=========================================================
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
             precision    recall  f1-score   support

          0       0.74      0.71      0.72        35
          1       0.00      0.00      0.00         9
          2       0.82      1.00      0.90        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.85      0.89      0.87       179

[[25  0 10  0  0]
 [ 9  0  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.svm.classes.SVC'>
=========================================================
SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
             precision    recall  f1-score   support

          0       0.79      0.97      0.87        35
          1       0.00      0.00      0.00         9
          2       0.98      1.00      0.99        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.90      0.94      0.92       179

[[34  0  1  0  0]
 [ 9  0  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

=========================================================
<class 'sklearn.neighbors.classification.KNeighborsClassifier'>
=========================================================
KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights='uniform')
             precision    recall  f1-score   support

          0       0.91      0.89      0.90        35
          1       0.60      0.67      0.63         9
          2       1.00      1.00      1.00        45
          3       1.00      1.00      1.00        41
          4       1.00      1.00      1.00        49

avg / total       0.96      0.96      0.96       179

[[31  4  0  0  0]
 [ 3  6  0  0  0]
 [ 0  0 45  0  0]
 [ 0  0  0 41  0]
 [ 0  0  0  0 49]] 

send already
